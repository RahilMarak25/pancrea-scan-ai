from flask import Flask, request, jsonify
from flask_cors import CORS
import os
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import load_model
import pydicom
from PIL import Image
import io
import logging
from werkzeug.utils import secure_filename

app = Flask(__name__)
CORS(app)  # Enable CORS for React frontend

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Load your trained CNN model
MODEL_PATH = "models/BEST_CNN2.keras"  # Path to your model in the project
model = None

def load_ml_model():
    """Load the CNN model"""
    global model
    try:
        if os.path.exists(MODEL_PATH):
            model = load_model(MODEL_PATH)
            logger.info("Model loaded successfully from local path")
        else:
            # Alternative: Load from Google Drive if model is not local
            # You would need to implement Google Drive API or use a direct download link
            logger.error(f"Model not found at {MODEL_PATH}")
            raise FileNotFoundError(f"Model file not found: {MODEL_PATH}")
    except Exception as e:
        logger.error(f"Error loading model: {e}")
        model = None

def preprocess_dicom(dicom_file):
    """
    Preprocess DICOM file for CNN input
    Adjust this function based on your model's expected input format
    """
    try:
        # Read DICOM file
        dicom_data = pydicom.dcmread(dicom_file)
        
        # Extract pixel array
        pixel_array = dicom_data.pixel_array
        
        # Normalize pixel values (adjust based on your preprocessing)
        pixel_array = pixel_array.astype(np.float32)
        
        # Normalize to 0-255 range if needed
        if pixel_array.max() > 255:
            pixel_array = (pixel_array / pixel_array.max()) * 255
        
        # Resize to model input size (adjust dimensions as needed)
        # Assuming your model expects 224x224 images
        img = Image.fromarray(pixel_array.astype(np.uint8))
        img = img.resize((224, 224))
        
        # Convert to RGB if needed (for CNN models expecting 3 channels)
        if len(np.array(img).shape) == 2:
            img = img.convert('RGB')
        
        # Convert to numpy array and normalize
        img_array = np.array(img) / 255.0
        
        return img_array
    
    except Exception as e:
        logger.error(f"Error preprocessing DICOM: {e}")
        return None

def predict_batch(images):
    """
    Make predictions on a batch of preprocessed images
    """
    if model is None:
        raise Exception("Model not loaded")
    
    try:
        # Stack images into batch
        batch = np.stack(images)
        
        # Make predictions
        predictions = model.predict(batch)
        
        # Process predictions based on your model output
        # Assuming binary classification (tumor/no tumor)
        if predictions.shape[1] == 1:
            # Single output sigmoid
            confidences = predictions.flatten()
            predicted_classes = (confidences > 0.5).astype(int)
        else:
            # Multi-class softmax
            confidences = np.max(predictions, axis=1)
            predicted_classes = np.argmax(predictions, axis=1)
        
        return predicted_classes, confidences
    
    except Exception as e:
        logger.error(f"Error during prediction: {e}")
        raise

@app.route('/api/analyze-dicom', methods=['POST'])
def analyze_dicom():
    """
    API endpoint to analyze DICOM files using the CNN model
    """
    try:
        if model is None:
            return jsonify({
                'error': 'Model not loaded. Please check server configuration.'
            }), 500
        
        # Check if files are present
        if 'dicom_files' not in request.files:
            return jsonify({'error': 'No DICOM files provided'}), 400
        
        files = request.files.getlist('dicom_files')
        if not files:
            return jsonify({'error': 'No files selected'}), 400
        
        processed_images = []
        valid_files = 0
        
        # Process each DICOM file
        for file in files:
            if file.filename == '':
                continue
                
            try:
                # Save file temporarily
                filename = secure_filename(file.filename)
                temp_path = f"/tmp/{filename}"
                file.save(temp_path)
                
                # Preprocess DICOM
                processed_img = preprocess_dicom(temp_path)
                
                if processed_img is not None:
                    processed_images.append(processed_img)
                    valid_files += 1
                
                # Clean up temp file
                os.remove(temp_path)
                
            except Exception as e:
                logger.error(f"Error processing file {file.filename}: {e}")
                continue
        
        if not processed_images:
            return jsonify({
                'error': 'No valid DICOM files could be processed'
            }), 400
        
        # Make predictions
        predicted_classes, confidences = predict_batch(processed_images)
        
        # Aggregate results (you can modify this logic)
        # For example, if any image shows tumor, classify as tumor
        has_tumor = np.any(predicted_classes == 1)  # Assuming 1 = tumor, 0 = no tumor
        overall_confidence = np.mean(confidences)
        
        # Format result
        result = "Tumor Detected" if has_tumor else "No Tumor Detected"
        
        response = {
            'prediction': result,
            'confidence': float(overall_confidence),
            'processed_files': valid_files,
            'total_files': len(files),
            'individual_predictions': predicted_classes.tolist(),
            'individual_confidences': confidences.tolist()
        }
        
        logger.info(f"Analysis complete: {result} with {overall_confidence:.3f} confidence")
        return jsonify(response)
    
    except Exception as e:
        logger.error(f"Error in analyze_dicom: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/health', methods=['GET'])
def health_check():
    """Health check endpoint"""
    model_status = "loaded" if model is not None else "not loaded"
    return jsonify({
        'status': 'healthy',
        'model_status': model_status
    })

if __name__ == '__main__':
    # Load model on startup
    load_ml_model()
    
    # Run the Flask app
    app.run(host='0.0.0.0', port=5000, debug=True)
