# backend/main.py - FastAPI backend for your React pancrea-scan-ai project

from fastapi import FastAPI, File, UploadFile, HTTPException, Depends, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
import os
import time
import logging
from typing import List, Optional
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import load_model
import pydicom
from PIL import Image
import tempfile
import shutil
from pydantic import BaseModel

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Initialize FastAPI app
app = FastAPI(
    title="Pancrea Scan AI - ML Backend",
    description="AI-powered pancreatic tumor detection backend",
    version="1.0.0"
)

# CORS middleware - Update with your React app URLs
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:3000", 
        "http://localhost:5173",  # Vite default port
        "https://your-vercel-app.vercel.app",  # Add your deployed frontend URL
        "https://lovable.dev"  # Your Lovable project URL
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Security
security = HTTPBearer(auto_error=False)

# Global variables
model = None
MODEL_VERSION = "CNN_v2.0"

# Model configuration for your 128x128 grayscale model
MODEL_CONFIG = {
    "input_shape": (128, 128, 1),  # Your model expects 128x128 grayscale images
    "classes": ["No Tumor", "Tumor Detected"],
    "preprocessing": {
        "normalize": True,
        "resize": (128, 128),
        "grayscale_to_rgb": False  # Keep as grayscale since your model expects 1 channel
    }
}

# Pydantic models for API responses
class PredictionResponse(BaseModel):
    prediction: str
    confidence: float
    processed_files: int
    total_files: int
    processing_time: float
    model_version: str

class HealthResponse(BaseModel):
    status: str
    model_loaded: bool
    model_version: Optional[str]
    timestamp: str

def load_ml_model():
    """Load the trained CNN model"""
    global model
    
    # Try different model paths
    model_paths = [
        "BEST_CNN2.keras",  # Root directory
        "models/BEST_CNN2.keras",  # Models folder
        "backend/BEST_CNN2.keras",  # Backend folder
        "backend/models/BEST_CNN2.keras",
        "/app/models/BEST_CNN2.keras",  # Docker path
        os.path.join(os.path.dirname(__file__), "BEST_CNN2.keras"),
        os.path.join(os.path.dirname(__file__), "models", "BEST_CNN2.keras"),
    ]
    
    for model_path in model_paths:
        try:
            if os.path.exists(model_path):
                model = load_model(model_path)
                logger.info(f"Model loaded successfully from {model_path}")
                return True
        except Exception as e:
            logger.error(f"Failed to load model from {model_path}: {e}")
            continue
    
    logger.error("Could not load model. Please ensure BEST_CNN2.keras is in your project directory.")
    return False

def preprocess_dicom_for_cnn(dicom_path: str) -> Optional[np.ndarray]:
    """
    Preprocess DICOM file for your 128x128 grayscale CNN model
    """
    try:
        # Read DICOM file
        dicom_data = pydicom.dcmread(dicom_path, force=True)
        
        # Extract pixel array
        if hasattr(dicom_data, 'pixel_array'):
            pixel_array = dicom_data.pixel_array
        else:
            logger.warning(f"No pixel array found in {dicom_path}")
            return None
        
        # Convert to float32 and normalize pixel values
        pixel_array = pixel_array.astype(np.float32)
        
        # Handle different bit depths
        if pixel_array.max() > 255:
            # Normalize to 0-255 range
            pixel_array = ((pixel_array - pixel_array.min()) / 
                          (pixel_array.max() - pixel_array.min()) * 255)
        
        # Convert to PIL Image for resizing
        img = Image.fromarray(pixel_array.astype(np.uint8))
        
        # Resize to 128x128 (your model's input size)
        img = img.resize((128, 128), Image.LANCZOS)
        
        # Ensure grayscale (your model expects single channel)
        if img.mode != 'L':
            img = img.convert('L')
        
        # Convert to numpy array
        img_array = np.array(img)
        
        # Add channel dimension: (128, 128) -> (128, 128, 1)
        img_array = np.expand_dims(img_array, axis=-1)
        
        # Normalize to 0-1 range
        img_array = img_array / 255.0
        
        return img_array
    
    except Exception as e:
        logger.error(f"Error preprocessing DICOM {dicom_path}: {e}")
        return None

def predict_tumor_batch(images: List[np.ndarray]) -> tuple:
    """Make predictions on a batch of preprocessed images"""
    if model is None:
        raise HTTPException(status_code=500, detail="Model not loaded")
    
    try:
        # Stack images into batch
        batch = np.stack(images)
        
        # Make predictions
        predictions = model.predict(batch, verbose=0)
        
        # Process predictions based on your model's output format
        if len(predictions.shape) == 2 and predictions.shape[1] == 1:
            # Binary classification with sigmoid output
            confidences = predictions.flatten()
            predicted_classes = (confidences > 0.5).astype(int)
        elif len(predictions.shape) == 2 and predictions.shape[1] == 2:
            # Binary classification with softmax output  
            confidences = np.max(predictions, axis=1)
            predicted_classes = np.argmax(predictions, axis=1)
        else:
            # Single output
            confidences = predictions.flatten()
            predicted_classes = (confidences > 0.5).astype(int)
        
        return predicted_classes, confidences
    
    except Exception as e:
        logger.error(f"Error during prediction: {e}")
        raise HTTPException(status_code=500, detail=f"Prediction failed: {str(e)}")

async def verify_auth(credentials: HTTPAuthorizationCredentials = Depends(security)):
    """Simple auth verification - integrate with your Supabase auth if needed"""
    if credentials is None:
        return None  # Allow anonymous access for now
    
    # TODO: Implement proper JWT token verification with Supabase
    # You can verify the JWT token with Supabase here
    return {"id": "user_123", "email": "user@example.com"}

@app.on_event("startup")
async def startup_event():
    """Load model on startup"""
    logger.info("Starting up Pancrea Scan AI ML Backend...")
    success = load_ml_model()
    if not success:
        logger.warning("Model could not be loaded. API will run but predictions will fail.")

@app.get("/health", response_model=HealthResponse)
async def health_check():
    """Health check endpoint"""
    from datetime import datetime
    
    return HealthResponse(
        status="healthy",
        model_loaded=model is not None,
        model_version=MODEL_VERSION if model is not None else None,
        timestamp=datetime.now().isoformat()
    )

@app.post("/api/v1/analyze-dicom", response_model=PredictionResponse)
async def analyze_dicom(
    dicom_files: List[UploadFile] = File(...),
    user_id: Optional[str] = Form(None),
    analysis_type: Optional[str] = Form("pancreatic_tumor_detection"),
    user = Depends(verify_auth)
):
    """
    Analyze DICOM files for pancreatic tumor detection
    This endpoint matches the format expected by your React component
    """
    start_time = time.time()
    
    if model is None:
        raise HTTPException(
            status_code=503, 
            detail="ML model not available. Please check server configuration."
        )
    
    if not dicom_files:
        raise HTTPException(status_code=400, detail="No DICOM files provided")
    
    if len(dicom_files) > 100:
        raise HTTPException(status_code=400, detail="Maximum 100 files allowed per request")
    
    # Create temporary directory for processing
    temp_dir = tempfile.mkdtemp()
    processed_images = []
    valid_files = 0
    
    try:
        # Process each DICOM file
        for i, file in enumerate(dicom_files):
            if not file.filename:
                continue
            
            # Check file extension
            if not (file.filename.lower().endswith('.dcm') or 
                   file.content_type == 'application/dicom'):
                logger.warning(f"Skipping non-DICOM file: {file.filename}")
                continue
            
            try:
                # Save uploaded file temporarily
                temp_file_path = os.path.join(temp_dir, f"temp_{i}_{file.filename}")
                
                with open(temp_file_path, "wb") as buffer:
                    shutil.copyfileobj(file.file, buffer)
                
                # Preprocess DICOM for your CNN model
                processed_img = preprocess_dicom_for_cnn(temp_file_path)
                
                if processed_img is not None:
                    processed_images.append(processed_img)
                    valid_files += 1
                else:
                    logger.warning(f"Could not process DICOM file: {file.filename}")
                
            except Exception as e:
                logger.error(f"Error processing file {file.filename}: {e}")
                continue
        
        if not processed_images:
            raise HTTPException(
                status_code=400, 
                detail="No valid DICOM files could be processed"
            )
        
        # Make predictions using your CNN model
        predicted_classes, confidences = predict_tumor_batch(processed_images)
        
        # Aggregate results
        # Strategy: If any image shows tumor (class 1), classify as tumor detected
        has_tumor = np.any(predicted_classes == 1)
        
        # Calculate overall confidence
        if has_tumor:
            # Use maximum confidence among tumor predictions
            tumor_confidences = confidences[predicted_classes == 1]
            overall_confidence = float(np.max(tumor_confidences))
            result = MODEL_CONFIG["classes"][1]  # "Tumor Detected"
        else:
            # Use average confidence for no-tumor predictions
            overall_confidence = float(np.mean(confidences))
            result = MODEL_CONFIG["classes"][0]  # "No Tumor"
        
        processing_time = time.time() - start_time
        
        # Log the result
        logger.info(f"Analysis complete: {result} (confidence: {overall_confidence:.3f}) "
                   f"for {valid_files} files in {processing_time:.2f}s")
        
        return PredictionResponse(
            prediction=result,
            confidence=overall_confidence,
            processed_files=valid_files,
            total_files=len(dicom_files),
            processing_time=processing_time,
            model_version=MODEL_VERSION
        )
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Unexpected error in analyze_dicom: {e}")
        raise HTTPException(status_code=500, detail=f"Analysis failed: {str(e)}")
    
    finally:
        # Cleanup temporary directory
        try:
            shutil.rmtree(temp_dir)
        except Exception as e:
            logger.error(f"Error cleaning up temp directory: {e}")

@app.get("/api/v1/model-info")
async def get_model_info():
    """Get information about the loaded model"""
    if model is None:
        raise HTTPException(status_code=503, detail="Model not loaded")
    
    return {
        "model_version": MODEL_VERSION,
        "input_shape": MODEL_CONFIG["input_shape"],
        "classes": MODEL_CONFIG["classes"],
        "preprocessing": MODEL_CONFIG["preprocessing"],
    }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        "main:app", 
        host="0.0.0.0", 
        port=8000, 
        reload=True,
        log_level="info"
    )
